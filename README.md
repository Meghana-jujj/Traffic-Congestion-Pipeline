# Traffic-Congestion-Pipeline
## ğŸš¦ Real-Time Traffic Congestion Monitoring & Alerting System

This project simulates real-time traffic data using Kafka and processes it using PySpark before storing results in a PostgreSQL database. The final visualizations are created in Tableau and Power BI. Everything is run locally, with no AWS or paid tools required â€” ideal for showcasing **end-to-end data engineering skills**.

## ğŸ’¡ Key Features

- ğŸ”„ **Kafka Producer** for streaming traffic data in real time  
- âš¡ **PySpark Structured Streaming** to clean, filter, and transform incoming data  
- ğŸ›¢ï¸ **PostgreSQL** for storing processed data  
- ğŸ“Š **Dashboards** in Power BI and Tableau to monitor congestion  
- ğŸ§± **Modular architecture** built like a real-world project  
- ğŸ–¼ï¸ Includes diagrams, SQL scripts, code, and sample data   

# Project Structure
traffic-congestion-pipeline/
â”œâ”€â”€ data/ # Simulated traffic CSV data files
â”œâ”€â”€ kafka_producer/ # Python script to stream data into Kafka
â”œâ”€â”€ spark_processor/ # PySpark streaming application
â”œâ”€â”€ database/ # PostgreSQL setup scripts and SQL files
â”œâ”€â”€ dashboards/
â”‚ â”œâ”€â”€ tableau/ # Tableau dashboards and screenshots
â”‚ â””â”€â”€ powerbi/ # Power BI dashboards and screenshots
â”œâ”€â”€ diagrams/ # Architecture diagrams and flowcharts
â”œâ”€â”€ requirements.txt # Python dependencies file
â”œâ”€â”€ .gitignore # Files to be ignored by Git
â””â”€â”€ README.md # Project documentation and overview

---

## ğŸ“¦ Tech Stack

| Layer             | Tools                      |
|------------------|----------------------------|
| Data Streaming   | Apache Kafka + Python      |
| Processing       | PySpark                    |
| Storage          | PostgreSQL                 |
| Visualization    | Tableau, Power BI          |
| Diagramming      | draw.io / Excalidraw       |

---

## ğŸ› ï¸ How to Run This Project

This project is still in development, and each step will be implemented in a separate folder with code, instructions, and visual outputs.

 âœ… Step 1: Setup Kafka, Zookeeper locally  
 âœ… Step 2: Create sample traffic data (CSV)  
 âœ… Step 3: Kafka Producer to stream traffic data  
 âœ… Step 4: PySpark consumer to process data  
 âœ… Step 5: Save output to PostgreSQL  
 âœ… Step 6: Build Tableau/Power BI dashboards  
 âœ… Step 7: Draw full architecture diagram  

---

## ğŸ“Š Sample Use Case

This project can simulate:
- Monitor city-wide traffic using IoT and GPS data  
- Identify slow-moving traffic in key areas  
- Trigger alerts when average speed drops below thresholds  
- Aggregate and visualize historical traffic trends

---

## ğŸ§  Learnings & Goals

This project was created to showcase real-world data engineering skills including:
- Working with real-time streaming data
- Building a Kafka â†’ Spark â†’ Database pipeline
- Creating professional, job-ready dashboards
- Documenting and deploying projects like a developer


# Link to Streamlit 
https://traffic-congestion-pipeline-sxgjydzmcptlfpzg5xzj6b.streamlit.app/

---

## ğŸ§‘â€ğŸ’» Author

**Meghana Jujjavarapu**  



